{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f82dc11",
   "metadata": {},
   "source": [
    "# üìä Analyse de Corr√©lation Dynamique des Cryptomonnaies\n",
    "\n",
    "## üéØ Objectif du Projet\n",
    "\n",
    "Ce notebook pr√©sente une **analyse compl√®te des corr√©lations dynamiques** entre cryptomonnaies majeures pour :\n",
    "- üìà **Identifier des groupes** d'actifs avec comportements similaires\n",
    "- üîÑ **Analyser l'√©volution temporelle** des corr√©lations sur 2 ans\n",
    "- üé™ **D√©tecter les changements de r√©gime** dans les march√©s crypto\n",
    "- üéØ **Fournir des insights** pour l'optimisation de portefeuille\n",
    "\n",
    "## üìã Structure du Notebook\n",
    "1. Configuration et imports\n",
    "2. Collecte des donn√©es\n",
    "3. Pr√©traitement des donn√©es\n",
    "4. Analyse de corr√©lation dynamique\n",
    "5. Clustering hi√©rarchique\n",
    "6. Visualisation en r√©seau des corr√©lations\n",
    "7. Clustering temporel avec K-Means\n",
    "8. D√©tection automatique des changements de r√©gime\n",
    "9. Clustering spectral optimis√©\n",
    "10. Rapport final et conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178882e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================================\n",
    "# üì¶ 1. CONFIGURATION ET IMPORTS\n",
    "# ================================================================================================\n",
    "\n",
    "# Suppression des warnings pour une sortie plus propre\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === IMPORTS PRINCIPAUX ===\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === VISUALISATION ===\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === DONN√âES FINANCI√àRES ===\n",
    "import yfinance as yf\n",
    "\n",
    "# === MACHINE LEARNING & CLUSTERING ===\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# === ANALYSE STATISTIQUE ===\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# === ANALYSE DE R√âSEAUX ===\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "# === CONFIGURATION GRAPHIQUES ===\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (14, 8),\n",
    "    'font.size': 11,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'figure.facecolor': 'white'\n",
    "})\n",
    "\n",
    "print(\"‚úÖ Tous les modules import√©s avec succ√®s\")\n",
    "print(f\"üìÖ Date d'ex√©cution : {datetime.datetime.now().strftime('%d/%m/%Y %H:%M')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46cc347",
   "metadata": {},
   "source": [
    "# üì¶ 2. COLLECTE DES DONN√âES\n",
    "\n",
    "T√©l√©chargement des donn√©es historiques sur **2 ans** pour les 9 cryptomonnaies s√©lectionn√©es:\n",
    "\n",
    "| Crypto | Symbole | Description |\n",
    "|--------|---------|-------------|\n",
    "| **Ethereum** | ETH-USD | Plateforme smart contracts |\n",
    "| **Binance Coin** | BNB-USD | Token exchange Binance |\n",
    "| **Ripple** | XRP-USD | R√©seau de paiements |\n",
    "| **Solana** | SOL-USD | Blockchain haute performance |\n",
    "| **Cardano** | ADA-USD | Blockchain acad√©mique |\n",
    "| **Polkadot** | DOT-USD | Interop√©rabilit√© blockchain |\n",
    "| **Shiba Inu** | SHIB-USD | Meme coin populaire |\n",
    "| **Litecoin** | LTC-USD | \"L'argent num√©rique\" |\n",
    "| **Avalanche** | AVAX-USD | Plateforme DeFi |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d06457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_crypto_data(symbols, num_days=730):\n",
    "    \"\"\"\n",
    "    Collecte les donn√©es historiques des cryptomonnaies\n",
    "    \n",
    "    Args:\n",
    "        symbols: Liste des symboles de cryptomonnaies\n",
    "        num_days: Nombre de jours d'historique (d√©faut: 730 = 2 ans)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec les prix de cl√¥ture quotidiens\n",
    "    \"\"\"\n",
    "    print(\"üìà Collecte des donn√©es en cours...\")\n",
    "    \n",
    "    # Configuration des dates\n",
    "    start = datetime.date.today() - datetime.timedelta(days=num_days)\n",
    "    end = datetime.date.today()\n",
    "    \n",
    "    print(f\"üìÖ P√©riode : {start} ‚Üí {end} ({num_days} jours)\")\n",
    "    \n",
    "    # T√©l√©chargement des donn√©es\n",
    "    data_close = pd.DataFrame()\n",
    "    success_count = 0\n",
    "    \n",
    "    for i, symbol in enumerate(symbols, 1):\n",
    "        try:\n",
    "            print(f\"   [{i:2d}/{len(symbols)}] {symbol:<10} ... \", end=\"\")\n",
    "            data = yf.download(symbol, start=start, end=end, interval=\"1d\", progress=False)\n",
    "            \n",
    "            if not data.empty:\n",
    "                data_close[symbol] = data[\"Close\"]\n",
    "                success_count += 1\n",
    "                print(\"‚úÖ\")\n",
    "            else:\n",
    "                print(\"‚ùå (Donn√©es vides)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ({str(e)[:30]}...)\")\n",
    "    \n",
    "    # Nettoyage des donn√©es\n",
    "    initial_length = len(data_close)\n",
    "    data_close.dropna(inplace=True)\n",
    "    final_length = len(data_close)\n",
    "    \n",
    "    print(f\"\\nüìä R√©sum√© :\")\n",
    "    print(f\"   ‚Ä¢ Cryptos collect√©es : {success_count}/{len(symbols)}\")\n",
    "    print(f\"   ‚Ä¢ Donn√©es brutes : {initial_length:,} jours\")\n",
    "    print(f\"   ‚Ä¢ Donn√©es nettoy√©es : {final_length:,} jours\")\n",
    "    print(f\"   ‚Ä¢ Donn√©es supprim√©es : {initial_length - final_length:,} jours\")\n",
    "    \n",
    "    return data_close\n",
    "\n",
    "# === CONFIGURATION DES CRYPTOMONNAIES ===\n",
    "crypto_symbols = [\n",
    "    \"ETH-USD\",   # Ethereum\n",
    "    \"BNB-USD\",   # Binance Coin\n",
    "    \"XRP-USD\",   # Ripple\n",
    "    \"SOL-USD\",   # Solana\n",
    "    \"ADA-USD\",   # Cardano\n",
    "    \"DOT-USD\",   # Polkadot\n",
    "    \"SHIB-USD\",  # Shiba Inu\n",
    "    \"LTC-USD\",   # Litecoin\n",
    "    \"AVAX-USD\"   # Avalanche\n",
    "]\n",
    "\n",
    "# === COLLECTE DES DONN√âES ===\n",
    "data_close = collect_crypto_data(crypto_symbols, num_days=730)\n",
    "\n",
    "# Aper√ßu des donn√©es\n",
    "print(f\"\\nüìã Aper√ßu des donn√©es collect√©es :\")\n",
    "print(data_close.tail())\n",
    "print(f\"\\nüìè Dimensions finales : {data_close.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a57b87",
   "metadata": {},
   "source": [
    "# üßÆ 3. PR√âTRAITEMENT DES DONN√âES\n",
    "\n",
    "Calcul des rendements logarithmiques pour normaliser les donn√©es et faciliter l'analyse statistique.\n",
    "Permet √©galement de stabiliser la variance et de r√©duire l'asym√©trie des distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0363a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_returns(price_data):\n",
    "    \"\"\"\n",
    "    Calcule les rendements logarithmiques √† partir des prix\n",
    "    \n",
    "    Args:\n",
    "        price_data: DataFrame avec les prix de cl√¥ture\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec les rendements logarithmiques\n",
    "    \"\"\"\n",
    "    print(\"üî¢ Calcul des rendements logarithmiques...\")\n",
    "    \n",
    "    # Calcul des rendements logarithmiques\n",
    "    log_returns = np.log(price_data / price_data.shift(1))\n",
    "    log_returns.dropna(inplace=True)\n",
    "    \n",
    "    print(f\"Rendements calcul√©s pour {len(log_returns)} jours\")\n",
    "    \n",
    "    # Statistiques descriptives\n",
    "    print(\"\\nüìà Statistiques des rendements:\")\n",
    "    print(f\"Rendement moyen : {log_returns.mean().mean():.4f}\")\n",
    "    print(f\"Volatilit√© moyenne : {log_returns.std().mean():.4f}\")\n",
    "    \n",
    "    return log_returns\n",
    "\n",
    "# Calcul des rendements\n",
    "log_returns = calculate_log_returns(data_close)\n",
    "\n",
    "# Visualisation des rendements\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "# Graphique des prix\n",
    "data_close.plot(ax=axes[0], title=\"√âvolution des Prix des Cryptomonnaies\", \n",
    "                legend=True, alpha=0.8)\n",
    "axes[0].set_ylabel(\"Prix (USD)\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique des rendements\n",
    "log_returns.plot(ax=axes[1], title=\"Rendements Logarithmiques\", \n",
    "                 legend=True, alpha=0.7)\n",
    "axes[1].set_ylabel(\"Rendements\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Pr√©traitement des donn√©es termin√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3206c3",
   "metadata": {},
   "source": [
    "# üìä 4. ANALYSE DE CORR√âLATION DYNAMIQUE\n",
    "\n",
    "Calcul des matrices de corr√©lation glissantes avec une fen√™tre de 30 jours pour capturer l'√©volution \n",
    "temporelle des relations entre cryptomonnaies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae70929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_correlations(returns_data, window=30):\n",
    "    \"\"\"\n",
    "    Calcule les corr√©lations glissantes pour analyser l'√©volution temporelle\n",
    "    \n",
    "    Args:\n",
    "        returns_data: DataFrame des rendements\n",
    "        window: Taille de la fen√™tre glissante (jours)\n",
    "    \n",
    "    Returns:\n",
    "        Liste des matrices de corr√©lation, dates correspondantes\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Calcul des corr√©lations glissantes (fen√™tre: {window} jours)...\")\n",
    "    \n",
    "    rolling_corrs = []\n",
    "    \n",
    "    # Calcul des corr√©lations glissantes avec barre de progression\n",
    "    for i in range(window, len(returns_data) + 1):\n",
    "        if i % 50 == 0:  # Affichage du progr√®s\n",
    "            progress = (i - window + 1) / (len(returns_data) - window + 1) * 100\n",
    "            print(f\"  Progression: {progress:.1f}%\")\n",
    "        \n",
    "        corr_matrix = returns_data.iloc[i-window:i].corr()\n",
    "        rolling_corrs.append(corr_matrix)\n",
    "    \n",
    "    # Dates correspondantes\n",
    "    dates = returns_data.index[window-1:]\n",
    "    \n",
    "    print(f\"‚úÖ {len(rolling_corrs)} matrices de corr√©lation calcul√©es\")\n",
    "    print(f\"P√©riode couverte: {dates[0].date()} √† {dates[-1].date()}\")\n",
    "    \n",
    "    return rolling_corrs, dates\n",
    "\n",
    "# Calcul des corr√©lations glissantes\n",
    "window_size = 30\n",
    "rolling_correlations, correlation_dates = calculate_rolling_correlations(log_returns, window_size)\n",
    "\n",
    "# Sauvegarde des donn√©es pour usage ult√©rieur\n",
    "latest_correlation = rolling_correlations[-1]\n",
    "latest_correlation.to_csv('last_correlation_matrix.csv')\n",
    "print(f\"\\nüíæ Derni√®re matrice de corr√©lation sauvegard√©e: last_correlation_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_correlation_evolution(rolling_corrs, dates):\n",
    "    \"\"\"\n",
    "    Visualise l'√©volution des corr√©lations dans le temps\n",
    "    \n",
    "    Args:\n",
    "        rolling_corrs: Liste des matrices de corr√©lation\n",
    "        dates: Dates correspondantes\n",
    "    \"\"\"\n",
    "    print(\"üìä Cr√©ation des visualisations de corr√©lation...\")\n",
    "    \n",
    "    # Configuration de la figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "    \n",
    "    # Indices pour d√©but, milieu, fin\n",
    "    indices = [0, len(rolling_corrs)//2, -1]\n",
    "    labels = [\"D√©but\", \"Milieu\", \"Fin\"]\n",
    "    \n",
    "    for i, (idx, label) in enumerate(zip(indices, labels)):\n",
    "        correlation_matrix = rolling_corrs[idx]\n",
    "        date = dates[idx] if idx != -1 else dates[idx]\n",
    "        \n",
    "        # Cr√©ation de la heatmap\n",
    "        sns.heatmap(correlation_matrix, \n",
    "                   annot=True, \n",
    "                   cmap=\"RdBu_r\", \n",
    "                   center=0,\n",
    "                   vmin=-1, \n",
    "                   vmax=1,\n",
    "                   ax=axes[i],\n",
    "                   fmt='.2f',\n",
    "                   square=True,\n",
    "                   cbar_kws={'label': 'Corr√©lation'})\n",
    "        \n",
    "        axes[i].set_title(f\"Corr√©lations {label}\\n({date.date()})\", \n",
    "                         fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Rotation des labels pour meilleure lisibilit√©\n",
    "        axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45, ha='right')\n",
    "        axes[i].set_yticklabels(axes[i].get_yticklabels(), rotation=0)\n",
    "    \n",
    "    plt.suptitle(\"√âvolution des Corr√©lations entre Cryptomonnaies\", \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Cr√©ation des visualisations\n",
    "correlation_figure = visualize_correlation_evolution(rolling_correlations, correlation_dates)\n",
    "\n",
    "# Analyse comparative d√©but vs fin\n",
    "print(\"\\nüîç Analyse comparative des corr√©lations:\")\n",
    "start_corr = rolling_correlations[0]\n",
    "end_corr = rolling_correlations[-1]\n",
    "correlation_change = end_corr - start_corr\n",
    "\n",
    "print(f\"Corr√©lation moyenne d√©but: {start_corr.mean().mean():.3f}\")\n",
    "print(f\"Corr√©lation moyenne fin: {end_corr.mean().mean():.3f}\")\n",
    "print(f\"Changement moyen: {correlation_change.mean().mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc471a9a",
   "metadata": {},
   "source": [
    "# üå≥ 5. CLUSTERING HI√âRARCHIQUE\n",
    "\n",
    "Application d'un clustering hi√©rarchique sur la matrice de corr√©lation la plus r√©cente pour \n",
    "identifier des groupes de cryptomonnaies ayant un comportement similaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f058dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hierarchical_clustering(correlation_matrix, method='ward', threshold=1.5):\n",
    "    \"\"\"\n",
    "    Effectue un clustering hi√©rarchique sur la matrice de corr√©lation\n",
    "    \n",
    "    Args:\n",
    "        correlation_matrix: Matrice de corr√©lation\n",
    "        method: M√©thode de linkage\n",
    "        threshold: Seuil pour former les clusters\n",
    "    \n",
    "    Returns:\n",
    "        Clusters, matrice de linkage, dictionnaire des clusters\n",
    "    \"\"\"\n",
    "    print(\"üå≥ Clustering hi√©rarchique en cours...\")\n",
    "    \n",
    "    # Calcul de la matrice de distance adapt√©e (pour corr√©lations n√©gatives)\n",
    "    distance_matrix = np.sqrt(0.5 * (1 - correlation_matrix))\n",
    "    \n",
    "    # Conversion en matrice condens√©e pour linkage\n",
    "    condensed_distances = squareform(distance_matrix)\n",
    "    \n",
    "    # Clustering hi√©rarchique\n",
    "    linkage_matrix = linkage(condensed_distances, method=method)\n",
    "    \n",
    "    # Visualisation du dendrogramme\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    dendrogram(linkage_matrix, \n",
    "               labels=correlation_matrix.columns, \n",
    "               leaf_rotation=90,\n",
    "               leaf_font_size=12)\n",
    "    plt.title(f\"Dendrogramme - Clustering Hi√©rarchique ({method.title()})\", \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(\"Cryptomonnaies\", fontsize=12)\n",
    "    plt.ylabel(\"Distance\", fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Attribution des clusters\n",
    "    clusters = fcluster(linkage_matrix, t=threshold, criterion='distance')\n",
    "    \n",
    "    # Affichage des r√©sultats\n",
    "    print(f\"\\nüìä R√©sultats du clustering (seuil: {threshold}):\")\n",
    "    cluster_dict = {}\n",
    "    for crypto, cluster in zip(correlation_matrix.columns, clusters):\n",
    "        if cluster not in cluster_dict:\n",
    "            cluster_dict[cluster] = []\n",
    "        cluster_dict[cluster].append(crypto)\n",
    "    \n",
    "    for cluster_id, cryptos in cluster_dict.items():\n",
    "        print(f\"  Cluster {cluster_id}: {', '.join(cryptos)}\")\n",
    "    \n",
    "    return clusters, linkage_matrix, cluster_dict\n",
    "\n",
    "# Application du clustering hi√©rarchique\n",
    "hierarchical_clusters, linkage_matrix, cluster_groups = perform_hierarchical_clustering(\n",
    "    latest_correlation, method='ward', threshold=1.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7586acda",
   "metadata": {},
   "source": [
    "# üï∏Ô∏è 6. VISUALISATION EN R√âSEAU DES CORR√âLATIONS\n",
    "\n",
    "Cr√©ation d'un graphe pour visualiser les corr√©lations fortes entre cryptomonnaies (seuil > 0.6).\n",
    "Cette repr√©sentation permet de mieux comprendre les relations entre les actifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea353738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_correlation_network(correlation_matrix, threshold=0.6, layout_seed=42):\n",
    "    \"\"\"\n",
    "    Cr√©e un graphe des corr√©lations fortes entre cryptomonnaies\n",
    "    \n",
    "    Args:\n",
    "        correlation_matrix: Matrice de corr√©lation\n",
    "        threshold: Seuil de corr√©lation pour cr√©er une ar√™te\n",
    "        layout_seed: Graine pour la disposition du graphe\n",
    "    \n",
    "    Returns:\n",
    "        Graphe NetworkX\n",
    "    \"\"\"\n",
    "    print(f\"üï∏Ô∏è Cr√©ation du graphe de corr√©lations (seuil: {threshold})...\")\n",
    "    \n",
    "    # Cr√©ation du graphe\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Ajout des ar√™tes pour corr√©lations > seuil\n",
    "    edges_added = 0\n",
    "    for i, j in combinations(correlation_matrix.columns, 2):\n",
    "        correlation_value = correlation_matrix.loc[i, j]\n",
    "        if correlation_value > threshold:\n",
    "            G.add_edge(i, j, weight=correlation_value)\n",
    "            edges_added += 1\n",
    "    \n",
    "    print(f\"  {edges_added} connexions fortes d√©tect√©es\")\n",
    "    \n",
    "    if edges_added == 0:\n",
    "        print(f\"  ‚ö†Ô∏è Aucune corr√©lation > {threshold} trouv√©e. R√©duction du seuil...\")\n",
    "        threshold = 0.4\n",
    "        for i, j in combinations(correlation_matrix.columns, 2):\n",
    "            correlation_value = correlation_matrix.loc[i, j]\n",
    "            if correlation_value > threshold:\n",
    "                G.add_edge(i, j, weight=correlation_value)\n",
    "                edges_added += 1\n",
    "        print(f\"  {edges_added} connexions d√©tect√©es avec seuil r√©duit √† {threshold}\")\n",
    "    \n",
    "    # Calcul de la disposition\n",
    "    pos = nx.spring_layout(G, seed=layout_seed, k=3, iterations=50)\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Calcul des poids des ar√™tes pour la visualisation\n",
    "    edge_weights = [G[u][v]['weight'] * 8 for u, v in G.edges()]\n",
    "    edge_colors = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "    \n",
    "    # Dessin du graphe\n",
    "    nx.draw_networkx_nodes(G, pos, \n",
    "                          node_color='lightblue', \n",
    "                          node_size=2000, \n",
    "                          alpha=0.8)\n",
    "    \n",
    "    nx.draw_networkx_edges(G, pos, \n",
    "                          width=edge_weights, \n",
    "                          edge_color=edge_colors,\n",
    "                          edge_cmap=plt.cm.Reds,\n",
    "                          alpha=0.7)\n",
    "    \n",
    "    nx.draw_networkx_labels(G, pos, \n",
    "                           font_size=12, \n",
    "                           font_weight='bold')\n",
    "    \n",
    "    # Ajout des poids sur les ar√™tes\n",
    "    edge_labels = {(u, v): f\"{G[u][v]['weight']:.2f}\" for u, v in G.edges()}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=10)\n",
    "    \n",
    "    plt.title(f\"R√©seau des Corr√©lations Fortes (> {threshold})\", \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistiques du r√©seau\n",
    "    print(f\"\\nüìà Statistiques du r√©seau:\")\n",
    "    print(f\"  N≈ìuds: {G.number_of_nodes()}\")\n",
    "    print(f\"  Ar√™tes: {G.number_of_edges()}\")\n",
    "    print(f\"  Densit√©: {nx.density(G):.3f}\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Cr√©ation du graphe de corr√©lations\n",
    "correlation_network = create_correlation_network(latest_correlation, threshold=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef8164",
   "metadata": {},
   "source": [
    "# ‚è∞ 7. CLUSTERING TEMPOREL AVEC K-MEANS\n",
    "\n",
    "Application de K-Means sur les matrices de corr√©lation aplaties pour identifier des r√©gimes \n",
    "temporels distincts dans les relations entre cryptomonnaies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c782b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_temporal_kmeans_clustering(rolling_correlations, n_clusters=3):\n",
    "    \"\"\"\n",
    "    Effectue un clustering K-Means temporel sur les matrices de corr√©lation\n",
    "    \n",
    "    Args:\n",
    "        rolling_correlations: Liste des matrices de corr√©lation\n",
    "        n_clusters: Nombre de clusters\n",
    "    \n",
    "    Returns:\n",
    "        Labels des clusters, mod√®le K-Means, donn√©es aplaties\n",
    "    \"\"\"\n",
    "    print(f\"‚è∞ Clustering temporel K-Means ({n_clusters} clusters)...\")\n",
    "    \n",
    "    # Fonction pour aplatir la matrice de corr√©lation (sans diagonale)\n",
    "    def flatten_correlation_matrix(correlation_matrix):\n",
    "        mask = ~np.eye(correlation_matrix.shape[0], dtype=bool)\n",
    "        return correlation_matrix.values[mask]\n",
    "    \n",
    "    # Aplatissement de toutes les matrices\n",
    "    flattened_data = np.array([\n",
    "        flatten_correlation_matrix(corr_matrix) \n",
    "        for corr_matrix in rolling_correlations\n",
    "    ])\n",
    "    \n",
    "    print(f\"  Donn√©es pr√©par√©es: {flattened_data.shape}\")\n",
    "    \n",
    "    # Application du K-Means\n",
    "    kmeans_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans_model.fit_predict(flattened_data)\n",
    "    \n",
    "    # Calcul des statistiques\n",
    "    unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    print(f\"  R√©partition des clusters:\")\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        percentage = count / len(cluster_labels) * 100\n",
    "        print(f\"    Cluster {label+1}: {count} jours ({percentage:.1f}%)\")\n",
    "    \n",
    "    return cluster_labels, kmeans_model, flattened_data\n",
    "\n",
    "def visualize_temporal_clusters(dates, cluster_labels, n_clusters=3):\n",
    "    \"\"\"\n",
    "    Visualise l'√©volution temporelle des clusters\n",
    "    \n",
    "    Args:\n",
    "        dates: Dates correspondantes\n",
    "        cluster_labels: Labels des clusters\n",
    "        n_clusters: Nombre de clusters\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Couleurs pour chaque cluster\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, n_clusters))\n",
    "    \n",
    "    # Graphique principal\n",
    "    for i in range(n_clusters):\n",
    "        mask = cluster_labels == i\n",
    "        plt.scatter(dates[mask], cluster_labels[mask] + 1, \n",
    "                   c=[colors[i]], label=f'R√©gime {i+1}', \n",
    "                   alpha=0.7, s=30)\n",
    "    \n",
    "    plt.ylabel(\"R√©gime de Corr√©lation\", fontsize=12)\n",
    "    plt.xlabel(\"Date\", fontsize=12)\n",
    "    plt.title(\"√âvolution des R√©gimes de Corr√©lation (K-Means Temporel)\", \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.yticks(range(1, n_clusters+1), [f'R√©gime {i+1}' for i in range(n_clusters)])\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Application du clustering temporel\n",
    "temporal_labels, kmeans_model, correlation_data = perform_temporal_kmeans_clustering(\n",
    "    rolling_correlations, n_clusters=3\n",
    ")\n",
    "\n",
    "# Visualisation\n",
    "visualize_temporal_clusters(correlation_dates, temporal_labels, n_clusters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e47a97",
   "metadata": {},
   "source": [
    "# üîç 8. D√âTECTION AUTOMATIQUE DES CHANGEMENTS DE R√âGIME\n",
    "\n",
    "Utilisation de l'analyse de variance et de la d√©tection de pics pour identifier \n",
    "automatiquement les p√©riodes de changement structurel dans les corr√©lations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e64506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_regime_changes(rolling_correlations, dates):\n",
    "    \"\"\"\n",
    "    D√©tecte automatiquement les changements de r√©gime bas√©s sur la variance des corr√©lations\n",
    "    \n",
    "    Args:\n",
    "        rolling_correlations: Liste des matrices de corr√©lation\n",
    "        dates: Dates correspondantes\n",
    "    \n",
    "    Returns:\n",
    "        Indices des changements de r√©gime, variance temporelle\n",
    "    \"\"\"\n",
    "    print(\"üîç D√©tection automatique des changements de r√©gime...\")\n",
    "    \n",
    "    # Calcul de la variance moyenne des corr√©lations dans le temps\n",
    "    variance_timeline = []\n",
    "    \n",
    "    for correlation_matrix in rolling_correlations:\n",
    "        # Extraction de la partie sup√©rieure de la matrice (sans diagonale)\n",
    "        upper_triangle = correlation_matrix.where(\n",
    "            np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    "        )\n",
    "        variance = np.nanvar(upper_triangle.values.flatten())\n",
    "        variance_timeline.append(variance)\n",
    "    \n",
    "    variance_timeline = np.array(variance_timeline)\n",
    "    \n",
    "    # D√©tection des pics de variance (changements de r√©gime potentiels)\n",
    "    threshold_height = np.mean(variance_timeline) + 1.5 * np.std(variance_timeline)\n",
    "    regime_change_indices, properties = find_peaks(\n",
    "        variance_timeline, \n",
    "        height=threshold_height,\n",
    "        distance=10  # Distance minimale entre pics\n",
    "    )\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # Graphique principal\n",
    "    plt.plot(dates, variance_timeline, \n",
    "             label='Variance des Corr√©lations', \n",
    "             linewidth=2, color='blue', alpha=0.7)\n",
    "    \n",
    "    # Ligne de seuil\n",
    "    plt.axhline(y=threshold_height, color='red', linestyle='--', \n",
    "                label=f'Seuil de d√©tection ({threshold_height:.4f})', alpha=0.7)\n",
    "    \n",
    "    # Points de changement de r√©gime\n",
    "    if len(regime_change_indices) > 0:\n",
    "        plt.scatter(dates[regime_change_indices], \n",
    "                   variance_timeline[regime_change_indices],\n",
    "                   color='red', s=100, marker='v', \n",
    "                   label='Changements de R√©gime D√©tect√©s', \n",
    "                   zorder=5)\n",
    "        \n",
    "        # Annotations\n",
    "        for idx in regime_change_indices:\n",
    "            plt.annotate(f'{dates[idx].strftime(\"%Y-%m-%d\")}',\n",
    "                        (dates[idx], variance_timeline[idx]),\n",
    "                        xytext=(10, 10), textcoords='offset points',\n",
    "                        bbox=dict(boxstyle='round,pad=0.3', fc='yellow', alpha=0.7),\n",
    "                        fontsize=10)\n",
    "    \n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Variance des Corr√©lations', fontsize=12)\n",
    "    plt.title('D√©tection Automatique des Changements de R√©gime', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # R√©sultats\n",
    "    print(f\"\\nüìä R√©sultats de la d√©tection:\")\n",
    "    print(f\"  Changements de r√©gime d√©tect√©s: {len(regime_change_indices)}\")\n",
    "    print(f\"  Variance moyenne: {np.mean(variance_timeline):.4f}\")\n",
    "    print(f\"  Variance maximale: {np.max(variance_timeline):.4f}\")\n",
    "    \n",
    "    if len(regime_change_indices) > 0:\n",
    "        print(f\"\\nüìÖ Dates des changements d√©tect√©s:\")\n",
    "        for idx in regime_change_indices:\n",
    "            date_str = dates[idx].strftime(\"%Y-%m-%d\")\n",
    "            variance_val = variance_timeline[idx]\n",
    "            print(f\"    {date_str} (variance: {variance_val:.4f})\")\n",
    "    else:\n",
    "        print(f\"  ‚ÑπÔ∏è Aucun changement de r√©gime significatif d√©tect√©\")\n",
    "    \n",
    "    return regime_change_indices, variance_timeline\n",
    "\n",
    "# D√©tection des changements de r√©gime\n",
    "regime_changes, variance_data = detect_regime_changes(rolling_correlations, correlation_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f92d3",
   "metadata": {},
   "source": [
    "# üåü 9. CLUSTERING SPECTRAL OPTIMIS√â\n",
    "\n",
    "Application du clustering spectral avec optimisation du nombre de clusters par analyse du score silhouette.\n",
    "Cette m√©thode est particuli√®rement adapt√©e aux donn√©es non-convexes et aux structures complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afcdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_spectral_clustering(correlation_matrix, max_clusters=6):\n",
    "    \"\"\"\n",
    "    Effectue un clustering spectral optimis√© sur la matrice de corr√©lation\n",
    "    \n",
    "    Args:\n",
    "        correlation_matrix: Matrice de corr√©lation\n",
    "        max_clusters: Nombre maximum de clusters √† tester\n",
    "    \n",
    "    Returns:\n",
    "        Labels des clusters, nombre optimal de clusters, scores silhouette\n",
    "    \"\"\"\n",
    "    print(\"üåü Clustering spectral avec optimisation...\")\n",
    "    \n",
    "    # Conversion de la matrice de corr√©lation en matrice de similarit√©\n",
    "    similarity_matrix = (correlation_matrix + 1) / 2  # Normalisation entre 0 et 1\n",
    "    \n",
    "    # Test de diff√©rents nombres de clusters\n",
    "    n_clusters_range = range(2, min(max_clusters+1, len(correlation_matrix.columns)))\n",
    "    silhouette_scores = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for n_clusters in n_clusters_range:\n",
    "        spectral = SpectralClustering(\n",
    "            n_clusters=n_clusters, \n",
    "            affinity='precomputed', \n",
    "            random_state=42\n",
    "        )\n",
    "        labels = spectral.fit_predict(similarity_matrix)\n",
    "        score = silhouette_score(similarity_matrix, labels, metric='precomputed')\n",
    "        silhouette_scores.append(score)\n",
    "        all_labels.append(labels)\n",
    "        \n",
    "        print(f\"  {n_clusters} clusters ‚Üí Score silhouette: {score:.3f}\")\n",
    "    \n",
    "    # Visualisation des scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(n_clusters_range, silhouette_scores, marker='o', linewidth=2, markersize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlabel('Nombre de clusters', fontsize=12)\n",
    "    plt.ylabel('Score silhouette', fontsize=12)\n",
    "    plt.title('Optimisation du nombre de clusters (Spectral Clustering)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xticks(list(n_clusters_range))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # S√©lection du meilleur nombre de clusters\n",
    "    best_idx = np.argmax(silhouette_scores)\n",
    "    optimal_n_clusters = list(n_clusters_range)[best_idx]\n",
    "    optimal_labels = all_labels[best_idx]\n",
    "    \n",
    "    # Affichage des r√©sultats\n",
    "    print(f\"\\nüéØ Nombre optimal de clusters: {optimal_n_clusters} (score: {silhouette_scores[best_idx]:.3f})\")\n",
    "    \n",
    "    # Organisation des r√©sultats par groupe\n",
    "    spectral_groups = {}\n",
    "    for i, crypto in enumerate(correlation_matrix.columns):\n",
    "        cluster_id = optimal_labels[i]\n",
    "        if cluster_id not in spectral_groups:\n",
    "            spectral_groups[cluster_id] = []\n",
    "        spectral_groups[cluster_id].append(crypto)\n",
    "    \n",
    "    for cluster_id, cryptos in spectral_groups.items():\n",
    "        print(f\"  Groupe {cluster_id + 1}: {', '.join(cryptos)}\")\n",
    "    \n",
    "    return optimal_labels, optimal_n_clusters, silhouette_scores, spectral_groups\n",
    "\n",
    "# Application du clustering spectral optimis√©\n",
    "spectral_labels, optimal_n_clusters, silhouette_scores, spectral_groups = perform_spectral_clustering(\n",
    "    latest_correlation, max_clusters=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1cfaf5",
   "metadata": {},
   "source": [
    "# üìã 10. RAPPORT FINAL ET CONCLUSION\n",
    "\n",
    "Synth√®se des analyses effectu√©es et des r√©sultats obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48656cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_report():\n",
    "    \"\"\"\n",
    "    G√©n√®re un rapport final avec tous les r√©sultats de l'analyse\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(\"üìã RAPPORT FINAL - ANALYSE DE CORR√âLATION DES CRYPTOMONNAIES\")\n",
    "    print(\"=\"*65)\n",
    "    \n",
    "    # 1. R√©sum√© des donn√©es\n",
    "    print(f\"\\nüìä DONN√âES ANALYS√âES:\")\n",
    "    print(f\"  ‚Ä¢ Cryptomonnaies: {len(crypto_symbols)}\")\n",
    "    print(f\"  ‚Ä¢ P√©riode d'analyse: {correlation_dates[0].date()} √† {correlation_dates[-1].date()}\")\n",
    "    print(f\"  ‚Ä¢ Nombre de jours: {len(data_close)}\")\n",
    "    print(f\"  ‚Ä¢ Matrices de corr√©lation calcul√©es: {len(rolling_correlations)}\")\n",
    "    \n",
    "    # 2. R√©sultats du clustering hi√©rarchique\n",
    "    print(f\"\\nüå≥ CLUSTERING HI√âRARCHIQUE:\")\n",
    "    for cluster_id, cryptos in cluster_groups.items():\n",
    "        print(f\"    Groupe {cluster_id}: {', '.join(cryptos)}\")\n",
    "    \n",
    "    # 3. R√©sultats du clustering spectral\n",
    "    print(f\"\\nüåü CLUSTERING SPECTRAL OPTIMAL ({optimal_n_clusters} clusters):\")\n",
    "    for cluster_id, cryptos in spectral_groups.items():\n",
    "        print(f\"    Groupe {cluster_id + 1}: {', '.join(cryptos)}\")\n",
    "    \n",
    "    # 4. Changements de r√©gime\n",
    "    print(f\"\\nüîç D√âTECTION DE R√âGIMES:\")\n",
    "    print(f\"  ‚Ä¢ Changements de r√©gime d√©tect√©s: {len(regime_changes)}\")\n",
    "    if len(regime_changes) > 0:\n",
    "        for idx in regime_changes:\n",
    "            print(f\"    - {correlation_dates[idx].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # 5. Statistiques temporelles\n",
    "    temporal_counts = np.bincount(temporal_labels)\n",
    "    print(f\"\\n‚è∞ R√âGIMES TEMPORELS (K-Means):\")\n",
    "    for i, count in enumerate(temporal_counts):\n",
    "        percentage = count / len(temporal_labels) * 100\n",
    "        print(f\"    R√©gime {i+1}: {count} jours ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 6. M√©triques de qualit√©\n",
    "    correlation_mean = latest_correlation.mean().mean()\n",
    "    correlation_std = np.std([corr.mean().mean() for corr in rolling_correlations])\n",
    "    \n",
    "    print(f\"\\nüìä M√âTRIQUES DE QUALIT√â:\")\n",
    "    print(f\"  ‚Ä¢ Corr√©lation moyenne actuelle: {correlation_mean:.3f}\")\n",
    "    print(f\"  ‚Ä¢ Volatilit√© des corr√©lations: {correlation_std:.3f}\")\n",
    "    print(f\"  ‚Ä¢ Score silhouette spectral: {silhouette_scores[optimal_n_clusters-2]:.3f}\")\n",
    "    \n",
    "    # 7. Recommandations\n",
    "    print(f\"\\nüí° RECOMMANDATIONS:\")\n",
    "    print(f\"  ‚Ä¢ Diversification: Investir dans diff√©rents clusters pour r√©duire le risque\")\n",
    "    print(f\"  ‚Ä¢ Surveillance: Monitorer les changements de r√©gime pour ajuster la strat√©gie\")\n",
    "    print(f\"  ‚Ä¢ Gestion des risques: Vigilance accrue en p√©riode de forte corr√©lation\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ ANALYSE TERMIN√âE AVEC SUCC√àS\")\n",
    "    print(\"=\"*65)\n",
    "\n",
    "# Sauvegarde des r√©sultats\n",
    "def save_all_results():\n",
    "    \"\"\"\n",
    "    Sauvegarde tous les r√©sultats dans des fichiers CSV\n",
    "    \"\"\"\n",
    "    print(\"\\nüíæ Sauvegarde des r√©sultats finaux...\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Rendements logarithmiques\n",
    "        log_returns.to_csv('log_returns_final.csv')\n",
    "        print(\"  ‚úÖ log_returns_final.csv\")\n",
    "        \n",
    "        # 2. R√©sultats du clustering\n",
    "        clustering_results = pd.DataFrame({\n",
    "            'cryptocurrency': latest_correlation.columns,\n",
    "            'hierarchical_cluster': hierarchical_clusters,\n",
    "            'spectral_cluster': spectral_labels + 1,  # +1 pour commencer √† 1\n",
    "            'temporal_cluster_final': temporal_labels[-1] + 1\n",
    "        })\n",
    "        clustering_results.to_csv('clustering_results_final.csv', index=False)\n",
    "        print(\"  ‚úÖ clustering_results_final.csv\")\n",
    "        \n",
    "        # 3. D√©tection de r√©gimes\n",
    "        regime_data = pd.DataFrame({\n",
    "            'date': correlation_dates,\n",
    "            'variance': variance_data,\n",
    "            'temporal_cluster': temporal_labels + 1\n",
    "        })\n",
    "        regime_data.to_csv('regime_detection_results.csv', index=False)\n",
    "        print(\"  ‚úÖ regime_detection_results.csv\")\n",
    "        \n",
    "        print(f\"\\nüéØ Tous les fichiers sauvegard√©s avec succ√®s!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Erreur lors de la sauvegarde: {e}\")\n",
    "\n",
    "# G√©n√©ration du rapport final\n",
    "generate_final_report()\n",
    "\n",
    "# Sauvegarde des r√©sultats\n",
    "save_all_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a644a",
   "metadata": {},
   "source": [
    "# üí° CONCLUSION ET RECOMMANDATIONS\n",
    "\n",
    "## üéØ Principaux R√©sultats\n",
    "\n",
    "L'analyse de corr√©lation dynamique des cryptomonnaies a r√©v√©l√© plusieurs insights importants :\n",
    "\n",
    "1. **Groupes de Cryptomonnaies** : Le clustering a identifi√© des groupes distincts avec des comportements corr√©l√©s\n",
    "2. **√âvolution Temporelle** : Les corr√©lations ne sont pas statiques et √©voluent significativement \n",
    "3. **Changements de R√©gime** : Des p√©riodes distinctes avec des structures de corr√©lation diff√©rentes\n",
    "4. **Diversification** : Possibilit√©s d'optimisation de portefeuille bas√©es sur les groupes identifi√©s\n",
    "\n",
    "## üíº Recommandations pour les Investisseurs\n",
    "\n",
    "- **Diversification** : R√©partir les investissements entre diff√©rents clusters\n",
    "- **Surveillance** : Monitorer les changements de r√©gime pour ajuster la strat√©gie\n",
    "- **Gestion des Risques** : √ätre vigilant pendant les p√©riodes de forte corr√©lation\n",
    "- **Opportunit√©s** : Exploiter les d√©corr√©lations temporaires pour des strat√©gies de trading\n",
    "\n",
    "## üîÆ Am√©liorations Futures\n",
    "\n",
    "- Int√©gration de donn√©es macro√©conomiques\n",
    "- Mod√®les pr√©dictifs pour anticiper les changements\n",
    "- Analyse en temps r√©el avec APIs\n",
    "- Extension √† d'autres classes d'actifs\n",
    "\n",
    "---\n",
    "\n",
    "**Projet r√©alis√© dans le cadre de l'analyse de donn√©es financi√®res - Data Mining**\n",
    "\n",
    "*Date de finalisation : Mai 2025*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
