#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Script de g√©n√©ration des matrices de corr√©lation pour cryptomonnaies
====================================================================

Ce script permet de g√©n√©rer des matrices de corr√©lation pour des donn√©es 
de cryptomonnaies √† partir de fichiers historiques. Il calcule les rendements 
logarithmiques et ensuite les corr√©lations glissantes.

Auteur: Data Mining Project
Date: Mai 2025
"""

import os
import datetime
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import yfinance as yf

# Configuration
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams.update({
    'figure.figsize': (14, 8),
    'font.size': 11,
    'axes.grid': True,
    'grid.alpha': 0.3,
    'figure.facecolor': 'white'
})

def collect_crypto_data(symbols, num_days=730):
    """
    Collecte les donn√©es historiques des cryptomonnaies
    
    Args:
        symbols: Liste des symboles de cryptomonnaies
        num_days: Nombre de jours d'historique (d√©faut: 730 = 2 ans)
    
    Returns:
        DataFrame avec les prix de cl√¥ture quotidiens
    """
    print("üìà Collecte des donn√©es en cours...")
    
    # Configuration des dates
    start = datetime.date.today() - datetime.timedelta(days=num_days)
    end = datetime.date.today()
    
    print(f"üìÖ P√©riode : {start} ‚Üí {end} ({num_days} jours)")
    
    # T√©l√©chargement des donn√©es
    data_close = pd.DataFrame()
    success_count = 0
    
    for i, symbol in enumerate(symbols, 1):
        try:
            print(f"   [{i:2d}/{len(symbols)}] {symbol:<10} ... ", end="")
            data = yf.download(symbol, start=start, end=end, interval="1d", progress=False)
            
            if not data.empty:
                data_close[symbol] = data["Close"]
                success_count += 1
                print("‚úÖ")
            else:
                print("‚ùå (Donn√©es vides)")
                
        except Exception as e:
            print(f"‚ùå ({str(e)[:30]}...)")
    
    # Nettoyage des donn√©es
    initial_length = len(data_close)
    data_close.dropna(inplace=True)
    final_length = len(data_close)
    
    print(f"\nüìä R√©sum√© :")
    print(f"   ‚Ä¢ Cryptos collect√©es : {success_count}/{len(symbols)}")
    print(f"   ‚Ä¢ Donn√©es brutes : {initial_length:,} jours")
    print(f"   ‚Ä¢ Donn√©es nettoy√©es : {final_length:,} jours")
    print(f"   ‚Ä¢ Donn√©es supprim√©es : {initial_length - final_length:,} jours")
    
    return data_close

def calculate_log_returns(price_data):
    """
    Calcule les rendements logarithmiques √† partir des prix
    
    Args:
        price_data: DataFrame avec les prix de cl√¥ture
    
    Returns:
        DataFrame avec les rendements logarithmiques
    """
    print("üî¢ Calcul des rendements logarithmiques...")
    
    # Calcul des rendements logarithmiques
    log_returns = np.log(price_data / price_data.shift(1))
    log_returns.dropna(inplace=True)
    
    print(f"Rendements calcul√©s pour {len(log_returns)} jours")

    # Normalisation (centrage-r√©duction)
    scaler = StandardScaler()
    log_returns_normalized = pd.DataFrame(
        scaler.fit_transform(log_returns),
        index=log_returns.index,
        columns=log_returns.columns
    )
    
    # Statistiques descriptives
    print("\nüìà Statistiques des rendements normalis√©s:")
    print(f"Rendement moyen : {log_returns_normalized.mean().mean():.4f}")
    print(f"Volatilit√© moyenne : {log_returns_normalized.std().mean():.4f}")
    
    return log_returns

def validate_data(returns_data):
    """
    Valide et nettoie les donn√©es de rendements
    
    Args:
        returns_data: DataFrame des rendements
    
    Returns:
        DataFrame nettoy√© ou None si probl√®me critique
    """
    print("üîç Validation des donn√©es...")
    
    # V√©rifications de base
    if returns_data.empty:
        print("‚ùå Erreur: DataFrame vide")
        return None
    
    if returns_data.isnull().all().all():
        print("‚ùå Erreur: Toutes les valeurs sont NaN")
        return None
    
    # Statistiques sur les donn√©es manquantes
    missing_pct = (returns_data.isnull().sum() / len(returns_data)) * 100
    print(f"üìä Donn√©es manquantes par colonne:")
    for col, pct in missing_pct.items():
        if pct > 0:
            print(f"  {col}: {pct:.1f}%")
        else:
            print(f"  {col}: ‚úÖ Aucune")
    
    # Statistiques descriptives
    print(f"\nüìà Statistiques des rendements:")
    print(f"  P√©riode: {returns_data.index[0].date()} √† {returns_data.index[-1].date()}")
    print(f"  Observations: {len(returns_data)}")
    print(f"  Cryptomonnaies: {list(returns_data.columns)}")
    
    # V√©rifier la variance (√©viter les s√©ries constantes)
    zero_variance = returns_data.var() == 0
    if zero_variance.any():
        print(f"‚ö†Ô∏è  Attention: Variance nulle d√©tect√©e pour {zero_variance[zero_variance].index.tolist()}")
    
    # Nettoyer les donn√©es
    clean_data = returns_data.dropna()
    if len(clean_data) < len(returns_data) * 0.8:
        print(f"‚ö†Ô∏è  Attention: {len(returns_data) - len(clean_data)} lignes supprim√©es (beaucoup de NaN)")
    
    print(f"‚úÖ Donn√©es valid√©es: {len(clean_data)} observations utilisables")
    return clean_data

def calculate_rolling_correlations(returns_data, window=30):
    """
    Calcule les corr√©lations glissantes pour analyser l'√©volution temporelle
    
    Args:
        returns_data: DataFrame des rendements
        window: Taille de la fen√™tre glissante (jours)
    
    Returns:
        Liste des matrices de corr√©lation, dates correspondantes
    """
    print(f"üîÑ Calcul des corr√©lations glissantes (fen√™tre: {window} jours)...")
    
    # Validation des donn√©es
    clean_data = validate_data(returns_data)
    if clean_data is None:
        return None, None
    
    if window > len(clean_data):
        print(f"‚ùå Erreur: Fen√™tre ({window}) > donn√©es disponibles ({len(clean_data)})")
        return None, None
    
    rolling_corrs = []
    dates = []
    
    for i in range(window, len(clean_data) + 1):
        if i % 50 == 0 or i == window:
            progress = (i - window + 1) / (len(clean_data) - window + 1) * 100
            print(f"  Progression: {progress:.1f}%")
        
        # Calculer la corr√©lation pour la fen√™tre actuelle
        window_data = clean_data.iloc[i-window:i]
        corr_matrix = window_data.corr()
        
        # V√©rifier que la matrice n'est pas vide
        if not corr_matrix.isnull().all().all():
            rolling_corrs.append(corr_matrix)
            dates.append(clean_data.index[i-1])
    
    if not rolling_corrs:
        print("‚ùå Erreur: Aucune matrice de corr√©lation valide calcul√©e")
        return None, None
    
    print(f"‚úÖ {len(rolling_corrs)} matrices de corr√©lation calcul√©es")
    print(f"P√©riode couverte: {dates[0].date()} √† {dates[-1].date()}")
    
    return rolling_corrs, dates

def save_correlation_matrices(rolling_correlations, dates, output_dir='output_corr'):
    """
    Sauvegarde les matrices de corr√©lation dans des fichiers CSV
    
    Args:
        rolling_correlations: Liste des matrices de corr√©lation
        dates: Dates correspondantes
        output_dir: R√©pertoire de sortie
    """
    print(f"üíæ Sauvegarde des matrices de corr√©lation...")
    
    # Cr√©er le r√©pertoire s'il n'existe pas
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"  R√©pertoire cr√©√©: {output_dir}")
    
    # Sauvegarder chaque matrice dans un fichier distinct
    for i, (corr_matrix, date) in enumerate(zip(rolling_correlations, dates)):
        if i % 50 == 0:
            progress = (i / len(rolling_correlations)) * 100
            print(f"  Progression: {progress:.1f}%")
        
        # Format du nom de fichier: YYYY-MM-DD_correlation_matrix.csv
        filename = f"{date.strftime('%Y-%m-%d')}_correlation_matrix.csv"
        file_path = os.path.join(output_dir, filename)
        
        # Sauvegarde
        corr_matrix.to_csv(file_path)
    
    # Sauvegarder la derni√®re matrice dans un fichier sp√©cial
    latest_file_path = os.path.join(output_dir, "latest_correlation_matrix.csv")
    rolling_correlations[-1].to_csv(latest_file_path)
    
    # Cr√©er un fichier avec les dates
    dates_df = pd.DataFrame({'date': dates})
    dates_file_path = os.path.join(output_dir, "correlation_dates.csv")
    dates_df.to_csv(dates_file_path, index=False)
    
    print(f"‚úÖ {len(rolling_correlations)} matrices sauvegard√©es dans {output_dir}")
    print(f"  Derni√®re matrice sauvegard√©e: {latest_file_path}")
    print(f"  Fichier des dates: {dates_file_path}")

def plot_sample_correlations(rolling_correlations, dates, n_samples=3):
    """
    Affiche des exemples de matrices de corr√©lation
    
    Args:
        rolling_correlations: Liste des matrices de corr√©lation
        dates: Dates correspondantes
        n_samples: Nombre d'exemples √† afficher
    """
    if not rolling_correlations or len(rolling_correlations) < n_samples:
        print("‚ùå Pas assez de matrices pour afficher des exemples")
        return
    
    # S√©lection d'indices uniform√©ment r√©partis
    indices = [0]
    if n_samples > 2:
        step = len(rolling_correlations) // (n_samples - 1)
        indices.extend([i * step for i in range(1, n_samples - 1)])
    indices.append(-1)
    
    # Cr√©ation de la figure
    fig, axes = plt.subplots(1, n_samples, figsize=(n_samples * 8, 7))
    
    # Colormap personnalis√©e
    colors = ['#d73027', '#ffffff', '#1a9850']
    cmap = plt.cm.colors.LinearSegmentedColormap.from_list('custom', colors, N=100)
    
    for i, idx in enumerate(indices):
        corr_matrix = rolling_correlations[idx]
        date = dates[idx]
        
        # Masque pour la diagonale sup√©rieure
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        
        # Affichage de la heatmap
        sns.heatmap(corr_matrix,
                    mask=mask,
                    annot=True,
                    cmap=cmap,
                    center=0,
                    vmin=-1,
                    vmax=1,
                    square=True,
                    fmt=".2f",
                    cbar_kws={'label': 'Corr√©lation'},
                    ax=axes[i],
                    linewidths=0.5)
        
        axes[i].set_title(f"Corr√©lation - {date.date()}", 
                         fontsize=14, fontweight='bold')
        axes[i].set_xticklabels(axes[i].get_xticklabels(), 
                               rotation=45, ha='right')
        axes[i].set_yticklabels(axes[i].get_yticklabels(), 
                               rotation=0)
    
    plt.suptitle("Exemples de Matrices de Corr√©lation", 
                 fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    plt.savefig("sample_correlation_matrices.png", dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """Point d'entr√©e principal du script"""
    print("=" * 80)
    print("üöÄ G√âN√âRATION DE MATRICES DE CORR√âLATION POUR CRYPTOMONNAIES")
    print("=" * 80)
    
    # Liste des cryptomonnaies √† analyser
    crypto_symbols = [
        "BTC-USD",   # Bitcoin
        "ETH-USD",   # Ethereum
        "BNB-USD",   # Binance Coin
        "XRP-USD",   # Ripple
        "SOL-USD",   # Solana
        "ADA-USD",   # Cardano
        "DOT-USD",   # Polkadot
        "SHIB-USD",  # Shiba Inu
        "LTC-USD",   # Litecoin
        "AVAX-USD"   # Avalanche
    ]
    
    # Param√®tres
    window_size = 30  # Taille de la fen√™tre glissante en jours
    num_days = 730    # 2 ans de donn√©es
    output_dir = "correlation_matrices"  # R√©pertoire de sortie
    
    # 1. Collecte des donn√©es
    data_close = collect_crypto_data(crypto_symbols, num_days)
    
    # Sauvegarder les prix de cl√¥ture
    data_close.to_csv("crypto_prices.csv")
    print("üíæ Prix de cl√¥ture sauvegard√©s dans crypto_prices.csv")
    
    # 2. Calcul des rendements logarithmiques
    log_returns = calculate_log_returns(data_close)
    
    # Sauvegarder les rendements logarithmiques
    log_returns.to_csv("log_returns.csv")
    print("üíæ Rendements logarithmiques sauvegard√©s dans log_returns.csv")
    
    # 3. Calcul des corr√©lations glissantes
    rolling_correlations, correlation_dates = calculate_rolling_correlations(log_returns, window_size)
    
    if rolling_correlations is not None:
        # 4. Sauvegarde des matrices
        save_correlation_matrices(rolling_correlations, correlation_dates, output_dir)
        
        # 5. Visualisation d'exemples
        plot_sample_correlations(rolling_correlations, correlation_dates, n_samples=3)
    
    print("\n‚úÖ TRAITEMENT TERMIN√â")
    print("=" * 80)

if __name__ == "__main__":
    main()
